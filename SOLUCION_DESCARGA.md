# ğŸ”§ Soluciones para Problema de Descarga - ODR Chatbot MVP

## ğŸš¨ Problema Identificado
No se puede descargar el modelo desde HuggingFace. AquÃ­ tienes **3 soluciones**:

## ğŸ¯ **SoluciÃ³n 1: Modelo Alternativo (Recomendado)**

### Descargar Phi-2 (mÃ¡s pequeÃ±o, ~1.5GB)
```powershell
# Ejecutar el script mejorado
powershell -ExecutionPolicy Bypass -File download_phi2.ps1
```

### Descarga Manual de Phi-2
1. Ve a: https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/phi-2.Q4_K_M.gguf
2. Descarga el archivo (1.5GB)
3. ColÃ³calo en `models/phi-2.Q4_K_M.gguf`

## ğŸ¯ **SoluciÃ³n 2: Usar Sin LLM (Funcionalidad BÃ¡sica)**

### ConfiguraciÃ³n sin modelo de LLM
```powershell
# Usar la versiÃ³n simplificada
Copy-Item docker-compose-simple.yml docker-compose.yml
docker compose up --build
```

**Funcionalidad disponible:**
- âœ… Subir PDFs
- âœ… Extraer texto y crear embeddings
- âœ… BÃºsqueda semÃ¡ntica
- âŒ Chat con LLM (necesita modelo)

## ğŸ¯ **SoluciÃ³n 3: Modelos MÃ¡s PequeÃ±os**

### OpciÃ³n A: TinyLlama (600MB)
```powershell
# Descargar versiÃ³n mÃ¡s pequeÃ±a
$url = "https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat.Q2_K.gguf"
$output = "models/tinyllama-1.1b-chat.Q2_K.gguf"
Invoke-WebRequest -Uri $url -OutFile $output
```

### OpciÃ³n B: Phi-1.5 (800MB)
```powershell
$url = "https://huggingface.co/TheBloke/phi-1_5-GGUF/resolve/main/phi-1_5.Q4_K_M.gguf"
$output = "models/phi-1_5.Q4_K_M.gguf"
Invoke-WebRequest -Uri $url -OutFile $output
```

## ğŸ”§ **SoluciÃ³n 4: Usar VPN o Proxy**

Si el problema es de conectividad:

### Con VPN
1. Conecta una VPN
2. Ejecuta el script de descarga
3. Desconecta la VPN

### Con Proxy
```powershell
# Configurar proxy si es necesario
$proxy = "http://tu-proxy:puerto"
$webClient = New-Object System.Net.WebClient
$webClient.Proxy = New-Object System.Net.WebProxy($proxy)
```

## ğŸš€ **Comandos de Prueba**

### Verificar conectividad
```powershell
# Probar acceso a HuggingFace
Invoke-WebRequest -Uri "https://huggingface.co" -UseBasicParsing

# Probar descarga pequeÃ±a
Invoke-WebRequest -Uri "https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat.Q2_K.gguf" -OutFile "test.gguf"
```

### Ejecutar sin modelo
```powershell
# Copiar configuraciÃ³n simple
Copy-Item docker-compose-simple.yml docker-compose.yml

# Levantar servicios bÃ¡sicos
docker compose up --build
```

## ğŸ“‹ **Estado de Funcionalidad**

| Componente | Con Modelo | Sin Modelo |
|------------|------------|------------|
| Subir PDF | âœ… | âœ… |
| Extraer texto | âœ… | âœ… |
| Embeddings | âœ… | âœ… |
| BÃºsqueda | âœ… | âœ… |
| Chat LLM | âœ… | âŒ |

## ğŸ¯ **RecomendaciÃ³n**

1. **Intenta SoluciÃ³n 1** (Phi-2) - Modelo mÃ¡s pequeÃ±o
2. **Si falla, usa SoluciÃ³n 2** (sin LLM) - Para probar funcionalidad bÃ¡sica
3. **Luego agrega el modelo** cuando tengas mejor conectividad

Â¡Cualquier soluciÃ³n te permitirÃ¡ probar el sistema! ğŸ‰




